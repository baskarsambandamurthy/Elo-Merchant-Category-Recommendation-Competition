{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4c047cfe1a8619fe6dee9306c01646998a39f47f"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Path = '../input/elo-ref-2-data-conversion/'\n",
    "# historical_transactions = pd.read_hdf(Path+'historical_transactions.hdf')\n",
    "# print('hist transactions read complete')\n",
    "# new_transactions = pd.read_hdf(Path+'new_transactions.hdf')\n",
    "# print('new transactions read complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "455197d4ea793721cdb47a2786a08c6966a88a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist transactions read complete\n",
      "new transactions read complete\n",
      "CPU times: user 1min 10s, sys: 13 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Path = '../input/elo-ref-2-data-conversion/'\n",
    "historical_transactions = pd.read_csv(Path+'historical_transactions.csv',index_col=0)\n",
    "print('hist transactions read complete')\n",
    "new_transactions = pd.read_csv(Path+'new_transactions.csv',index_col=0)\n",
    "print('new transactions read complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5fb0be120c51c0c4988ff684e0686f4457a250aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1582.53 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 102.97 Mb (54.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions= reduce_mem_usage(historical_transactions)\n",
    "new_transactions= reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "60aa2d17ac90fdda7299750a32838565cd658de4"
   },
   "outputs": [],
   "source": [
    "# cardid ='C_ID_749cfc0c3a'\n",
    "# new_transactions[historical_transactions['card_id']==cardid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "75c7f78dd48498cd60c5a3cb8012341dce9bce49"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train = pd.read_hdf('../input/elo-preproc-3/train_preproc.hdf')\n",
    "# test = pd.read_hdf('../input/elo-preproc-3/test_preproc.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f521c13b07ca2a14f00662c6c79e16404f980715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 160 ms, total: 8.16 s\n",
      "Wall time: 8.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/elo-preproc-3/train_preproc.csv',index_col=0)\n",
    "test = pd.read_csv('../input/elo-preproc-3/test_preproc.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c88bb40d45cea4454d6ef54a9809fe6f5894b6c7"
   },
   "outputs": [],
   "source": [
    "# pearsonr(train['new_hist_category_1_mean'].fillna(-10000),train['hist_category_1_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bd822057ddf233807072f4c605c1f793134a46a9"
   },
   "outputs": [],
   "source": [
    "mask = train['target'] < -30\n",
    "train['outliers'] = 0\n",
    "train.loc[mask,'outliers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5e6dcf8bec5adaa7bb0d61dcb4eace65595c8f87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6.07,  170.  ,  898.04, 1050.12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.array([-0.737793,-0.491455,0.602539,0.831055]) / 0.00150265118 + 497.06,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e0197cb78f09a74d76194c05de75c4e41834c99e"
   },
   "outputs": [],
   "source": [
    "new_transactions['purchase_amount'] = new_transactions['purchase_amount'].astype('float32')\n",
    "new_transactions['purchase_amount_new'] = np.round(new_transactions['purchase_amount'] / 0.00150265118 + 497.06,2)\n",
    "historical_transactions['purchase_amount_new'] = np.round(historical_transactions['purchase_amount'] / 0.00150265118 + 497.06,2)\n",
    "# train['target_raw'] = 2**train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "a7c9ee31ec0f51f62bd1a4c7e3545bb01d589e3d"
   },
   "outputs": [],
   "source": [
    "# historical_transactions = pd.merge(historical_transactions,train[['target','outliers','card_id']],on='card_id',how='left')\n",
    "# print('history merge complete')\n",
    "\n",
    "# new_transactions = pd.merge(new_transactions,train[['target','outliers','card_id']],on='card_id',how='left')\n",
    "# print('new merge complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ef919a0f728ce3ddb3f5a437c7b94038e65b6ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -8,  -7,  -6,  -5, -11,   0,  -3,  -9,  -4,  -1, -13, -10, -12,\n",
       "        -2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_transactions['month_lag'].unique())\n",
    "historical_transactions['month_lag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "ea7803e7aaf8e0f9497e66930c36a2fef3771f0a"
   },
   "outputs": [],
   "source": [
    "# # scaler = MinMaxScaler(feature_range=(1,2))\n",
    "# # scaler.fit(historical_transactions['purchase_amount'].values.reshape(-1,1))\n",
    "# # scaled= scaler.transform(historical_transactions['purchase_amount'].values.reshape(-1,1))\n",
    "# for df in [historical_transactions,new_transactions]:\n",
    "#     mask = (df['installments']==-1) | (df['installments']==999)\n",
    "#     df.loc[mask,'purchase_amount_per_install'] = df[mask]['purchase_amount_new'] \n",
    "#     df.loc[~mask,'purchase_amount_per_install'] = df[~mask]['purchase_amount_new'] /  (df[~mask]['installments'] + 1)\n",
    "#     print(df['purchase_amount_per_install'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "b543f41c281fba5ebe633f24325dad865372d0fc"
   },
   "outputs": [],
   "source": [
    "hist_gp = historical_transactions.groupby(['card_id','month_lag']).agg({'purchase_amount_new':'mean'}).reset_index()\n",
    "new_gp = new_transactions.groupby(['card_id','month_lag']).agg({'purchase_amount_new':'mean',}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8ea3e43cb693c02e2b4441985449b09433b63619"
   },
   "outputs": [],
   "source": [
    "# hist_gp = historical_transactions.groupby(['card_id','month_lag']).agg({'purchase_amount_new':'sum','target': 'first','outliers':'first'}).reset_index()\n",
    "# new_gp = new_transactions.groupby(['card_id','month_lag']).agg({'purchase_amount_new':'sum','target':'first','outliers':'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "163700a29a951d6863279ab58c03713cf69e0c94"
   },
   "outputs": [],
   "source": [
    "def filter_monthlag(cardids,trans,month_lag,purch_col='purchase_amount_new'):\n",
    "    trans_filt = trans[trans['month_lag']==month_lag]\n",
    "    missed_cardids=set(cardids.unique()).difference(set(trans_filt['card_id'].unique())) \n",
    "    miss_df = pd.DataFrame()\n",
    "    miss_df['card_id'] = np.array(list(missed_cardids))\n",
    "    miss_df['month_lag'] = 1000\n",
    "    miss_df[purch_col] = 0\n",
    "    trans_filt =pd.concat([trans_filt,miss_df],axis=0)\n",
    "    trans_filt.sort_values('card_id',inplace=True)\n",
    "    trans_filt.reset_index(inplace=True)\n",
    "    return trans_filt\n",
    "\n",
    "def filter_monthlag_max(cardids,trans,month_lag,tofilter=True,purch_col='purchase_amount_new'):\n",
    "    if tofilter:\n",
    "        trans_filt = trans[trans['month_lag']<month_lag]\n",
    "    else:\n",
    "        trans_filt = trans\n",
    "        \n",
    "#     trans_filt = trans_filt.loc[trans_filt.groupby('card_id')['month_lag'].idxmax()]\n",
    "    \n",
    "    trans_filt['index_orig'] = trans_filt.index\n",
    "    trans_filt = trans_filt.sort_values(\"month_lag\",ascending=False).groupby(\"card_id\", as_index=False).first()\n",
    "    missed_cardids=set(cardids.unique()).difference(set(trans_filt['card_id'].unique())) \n",
    "    miss_df = pd.DataFrame()\n",
    "    miss_df['card_id'] = np.array(list(missed_cardids))\n",
    "    miss_df['month_lag'] = 1000\n",
    "    miss_df[purch_col] = 0\n",
    "    miss_df.index = np.repeat([1E+20],miss_df.shape[0]) \n",
    "    print('miss_df.shape:',miss_df.shape)\n",
    "#     print('miss_df.index:',miss_df.index)\n",
    "    trans_filt =pd.concat([trans_filt,miss_df],axis=0)\n",
    "    trans_filt.sort_values('card_id',inplace=True)\n",
    "#     print('trans_filt.index:',trans_filt.index)\n",
    "    trans_filt.reset_index(inplace=True)\n",
    "    print('trans filt shape final:',trans_filt.shape)\n",
    "#     print('trans_filt[index] after:',trans_filt['index'].nunique())\n",
    "    return trans_filt\n",
    "\n",
    "def gen_lagratio(cardids,numerator,denominator,newcolname,train,test):\n",
    "    ratio_df = pd.DataFrame()\n",
    "    ratio_df['card_id'] = cardids\n",
    "\n",
    "    eps = 1E-10\n",
    "    ratio_df[newcolname] = numerator / (denominator + eps)\n",
    "    ratio_df.loc[numerator==0,newcolname] = 0\n",
    "\n",
    "    #merge with train and test\n",
    "    train = pd.merge(train, ratio_df, on='card_id', how='left')\n",
    "    test = pd.merge(test, ratio_df, on='card_id', how='left')\n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "a123e8f853c801ee38461c857343b2c91518151e"
   },
   "outputs": [],
   "source": [
    "hist_gp.sort_values('card_id').reset_index(inplace=True)\n",
    "new_gp.sort_values('card_id').reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5836a8ca9d8a72f1fd06112616d633db0f8a6736"
   },
   "outputs": [],
   "source": [
    "# lagratiocols = [col for col in train.columns if ('lag_' in col) and (('_ratio') in col)]\n",
    "# train.drop(lagratiocols,inplace=True,axis=1)\n",
    "# test.drop(lagratiocols,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "53088741a318d51f2cb082930cecf979e6fc8e60"
   },
   "outputs": [],
   "source": [
    "purch_col ='purchase_amount_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "d2c81ec10ed612e0d4b72a413aeb33c98ca966e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "# Lag 0 / Lag next ratio\n",
    "month_lag =0\n",
    "hist_gp_lag_0 = filter_monthlag(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "hist_gp_lag_next = filter_monthlag_max(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "\n",
    "train,test = gen_lagratio(hist_gp_lag_0['card_id'],hist_gp_lag_0[purch_col],\n",
    "             hist_gp_lag_next[purch_col],'lag_avg_0_ratio',train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "99901d8a522b3269232cd615da4626f9aec14f38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (1560, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "# Lag -1 / Lag next ratio\n",
    "month_lag = -1\n",
    "hist_gp_lag_m_1 = filter_monthlag(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "hist_gp_lag_m_1_next = filter_monthlag_max(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "\n",
    "train,test = gen_lagratio(hist_gp_lag_m_1['card_id'],hist_gp_lag_m_1[purch_col],\n",
    "             hist_gp_lag_m_1_next[purch_col],'lag_avg_-1_ratio',train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "afc43524d19e2ee9090c805ac25c38208032f3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "#Lag 0  and Lag -1 ratio\n",
    "# For second maximum , remove records by using drop (first max) and then generate maximum again\n",
    "month_lag =-1\n",
    "hist_gp_lag_m_1_next_2 = filter_monthlag_max(hist_gp['card_id'],\n",
    "                                             hist_gp.drop(index=hist_gp_lag_m_1_next['index_orig'],errors='ignore',axis=0),\n",
    "                                             month_lag,tofilter=False,purch_col=purch_col)\n",
    "numerator = hist_gp_lag_0[purch_col] + hist_gp_lag_m_1[purch_col]\n",
    "denominator = (hist_gp_lag_m_1_next[purch_col] + hist_gp_lag_m_1_next_2[purch_col] )\n",
    "\n",
    "train,test = gen_lagratio(hist_gp_lag_m_1_next_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_0_2m_ratio',train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "79bf0bb20f3851ebfc39ed8cbdeedc3a7a11d550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (25718, 3)\n",
      "trans filt shape final: (325540, 5)\n",
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n",
      "miss_df.shape: (96, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "#Lag 0  and Lag -1 and Lag -2 ratio\n",
    "\n",
    "month_lag = -2\n",
    "hist_gp_lag_m_2 = filter_monthlag(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "hist_gp_lag_m_2_next = filter_monthlag_max(hist_gp['card_id'],hist_gp,month_lag,purch_col=purch_col)\n",
    "idx1 = hist_gp_lag_m_2_next['index_orig']\n",
    "\n",
    "hist_gp_lag_m_2_next_2 = filter_monthlag_max(hist_gp['card_id'],\n",
    "                                             hist_gp.drop(index=idx1,axis=0,errors='ignore',),\n",
    "                                             month_lag,tofilter=False,purch_col=purch_col)\n",
    "idx2 = hist_gp_lag_m_2_next_2['index_orig']\n",
    "idx_comb = pd.concat([idx1,idx2])\n",
    "\n",
    "# idx_comb = set(list(idx1)).union(set(list(idx1)))\n",
    "hist_gp_lag_m_2_next_3 = filter_monthlag_max(hist_gp['card_id'],\n",
    "                                             hist_gp.drop(index=idx_comb,axis=0,errors='ignore',),\n",
    "                                             month_lag,tofilter=False,purch_col=purch_col)\n",
    "\n",
    "numerator = hist_gp_lag_0[purch_col] + hist_gp_lag_m_1[purch_col] + \\\n",
    "            hist_gp_lag_m_2[purch_col]\n",
    "denominator = (hist_gp_lag_m_2_next[purch_col] +\\\n",
    "               hist_gp_lag_m_2_next_2[purch_col] +\\\n",
    "               hist_gp_lag_m_2_next_3[purch_col] )\n",
    "\n",
    "train,test = gen_lagratio(hist_gp_lag_m_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_0_3m_ratio',train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "f7fe0259fcc94d7f901a7f8e37bb39b320119469"
   },
   "outputs": [],
   "source": [
    "#New transactions as future trans\n",
    "new_gp_lag_2 = filter_monthlag(hist_gp['card_id'],new_gp,2,purch_col=purch_col)\n",
    "new_gp_lag_1 = filter_monthlag(hist_gp['card_id'],new_gp,1,purch_col=purch_col)\n",
    "\n",
    "numerator = new_gp_lag_2[purch_col] \n",
    "denominator = new_gp_lag_1[purch_col] \n",
    "train,test = gen_lagratio(new_gp_lag_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_new_ratio',train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "139abf7a1daf436028e3288dfda406f064d9ee86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n",
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "#New transactions as future trans\n",
    "# new_gp_lag_2 = filter_monthlag(hist_gp['card_id'],new_gp,2)\n",
    "# new_gp_lag_1 = filter_monthlag(hist_gp['card_id'],new_gp,1)\n",
    "\n",
    "hist_gp_lag_0_next = filter_monthlag_max(hist_gp['card_id'],hist_gp,1,purch_col=purch_col)\n",
    "hist_gp_lag_0_next_2 = filter_monthlag_max(hist_gp['card_id'],\n",
    "                                             hist_gp.drop(index=hist_gp_lag_0_next['index_orig'],errors='ignore',axis=0),\n",
    "                                             0,tofilter=False,purch_col=purch_col)\n",
    "\n",
    "numerator = new_gp_lag_2[purch_col] + new_gp_lag_1[purch_col]\n",
    "denominator = (hist_gp_lag_0_next[purch_col] + hist_gp_lag_0_next_2[purch_col] )\n",
    "\n",
    "train,test = gen_lagratio(new_gp_lag_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_new_2m_ratio',train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "ec62feccc44500ad83ecbfb95c75dcb08ef78ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n",
      "miss_df.shape: (0, 3)\n",
      "trans filt shape final: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "#New transactions as future trans\n",
    "# new_gp_lag_2 = filter_monthlag(hist_gp['card_id'],new_gp,2)\n",
    "# new_gp_lag_1 = filter_monthlag(hist_gp['card_id'],new_gp,1)\n",
    "\n",
    "hist_gp_lag_0_next = filter_monthlag_max(hist_gp['card_id'],hist_gp,1,purch_col=purch_col)\n",
    "hist_gp_lag_0_next_2 = filter_monthlag_max(hist_gp['card_id'],\n",
    "                                             hist_gp.drop(index=hist_gp_lag_0_next['index_orig'],errors='ignore',axis=0),\n",
    "                                             0,tofilter=False,purch_col=purch_col)\n",
    "\n",
    "numerator =(new_gp_lag_2[purch_col] + new_gp_lag_1[purch_col])\n",
    "denominator =  (hist_gp_lag_0_next[purch_col]+hist_gp_lag_0_next_2[purch_col]) / 2\n",
    "\n",
    "train,test = gen_lagratio(new_gp_lag_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_new_2m_avg_ratio',train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "ca6262f59b121fc9ff3febccf4a009a79a42a19b"
   },
   "outputs": [],
   "source": [
    "#New transactions as future trans\n",
    "numerator = new_gp_lag_1[purch_col] \n",
    "denominator = hist_gp_lag_0_next[purch_col] \n",
    "train,test = gen_lagratio(new_gp_lag_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_new_1_to_0_ratio',train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "6c179bafd92876c00cf8682c60e5c69beb2c52b2"
   },
   "outputs": [],
   "source": [
    "#New transactions as future trans\n",
    "numerator = new_gp_lag_2[purch_col] \n",
    "denominator = hist_gp_lag_0_next[purch_col] \n",
    "train,test = gen_lagratio(new_gp_lag_2['card_id'],numerator,\n",
    "             denominator,'lag_avg_new_2_to_0_ratio',train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "f5a18c02b912cca8346326c322af92ef3ebe029f"
   },
   "outputs": [],
   "source": [
    "train['target_raw'] = 2**train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "1d33bda79138ae19f0f9056a2346c5ee8c30957d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_avg_new_ratio correlation:-0.01558785635249433 pval: 2.4731630308077357e-12 \n",
      "lag_avg_new_2m_ratio correlation:-0.049613152605940423 pval: 3.1348491572185834e-110 \n",
      "lag_avg_new_1_to_0_ratio correlation:-0.0031085230133148347 pval: 0.16246921052683105 \n",
      "lag_avg_new_2_to_0_ratio correlation:9.442899497129436e-05 pval: 0.9661546600181022 \n",
      "lag_avg_-1_ratio correlation:0.0031881377290726184 pval: 0.1519750251110043 \n",
      "lag_avg_0_ratio correlation:0.0003785527724988443 pval: 0.8649296801605051 \n",
      "lag_avg_0_3m_ratio correlation:0.0005855441034103025 pval: 0.7924629722567607 \n",
      "lag_avg_0_2m_ratio correlation:0.0007824465115873083 pval: 0.7251445727653929 \n",
      "hist_month_nunique correlation:-0.019252469457306354 pval: 5.065825334551969e-18 \n"
     ]
    }
   ],
   "source": [
    "ratiocols = ['lag_avg_new_ratio','lag_avg_new_2m_ratio','lag_avg_new_1_to_0_ratio','lag_avg_new_2_to_0_ratio',\n",
    "#              'lag_new_2m_avg_ratio',\n",
    "             'lag_avg_-1_ratio','lag_avg_0_ratio','lag_avg_0_3m_ratio','lag_avg_0_2m_ratio']\n",
    "# ratiocols = ['lag_new_2m_ratio']\n",
    "for col in ratiocols:\n",
    "    coeff,pval= stats.pearsonr(train[col].values,\n",
    "                           train['target'].values)\n",
    "    print('{0} correlation:{1} pval: {2} '.format(col,coeff,pval))\n",
    "    \n",
    "# coeff,pval= stats.pearsonr(train[ratiocols].mean(axis=1).values,\n",
    "#                        train['target_raw'].values)\n",
    "col = 'hist_month_nunique'\n",
    "coeff,pval= stats.pearsonr(train[col].values,\n",
    "                       train['target'].values)\n",
    "print('{0} correlation:{1} pval: {2} '.format(col,coeff,pval))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "9baae421ddc86702c17f91a616cc6ecdaaedf587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hist_gp,new_gp\n",
    "del hist_gp_lag_0_next, hist_gp_lag_0_next_2, numerator, denominator\n",
    "del new_gp_lag_1, new_gp_lag_2\n",
    "del hist_gp_lag_0,hist_gp_lag_next\n",
    "del hist_gp_lag_m_1,hist_gp_lag_m_1_next,hist_gp_lag_m_1_next_2\n",
    "del hist_gp_lag_m_2,hist_gp_lag_m_2_next,hist_gp_lag_m_2_next_3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "9c395c4f293f009e63c50f1d5d007f6129358b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.911236e+07\n",
      "mean     1.370152e+02\n",
      "std      1.123521e+05\n",
      "min      1.000000e+02\n",
      "25%      1.026552e+02\n",
      "50%      1.058558e+02\n",
      "75%      1.143653e+02\n",
      "max      6.010605e+08\n",
      "Name: purchase_amount_scaled, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     1.422354e+02\n",
      "std      1.122055e+05\n",
      "min      7.698087e+00\n",
      "25%      5.299028e+01\n",
      "50%      1.009767e+02\n",
      "75%      1.052593e+02\n",
      "max      6.010605e+08\n",
      "Name: purchase_amount_per_install, dtype: float64\n",
      "count    1.963031e+06\n",
      "mean     1.194826e+02\n",
      "std      6.926756e+01\n",
      "min      1.000000e+02\n",
      "25%      1.030273e+02\n",
      "50%      1.072266e+02\n",
      "75%      1.165527e+02\n",
      "max      2.649971e+04\n",
      "Name: purchase_amount_scaled, dtype: float64\n",
      "count    1.963031e+06\n",
      "mean     8.482602e+01\n",
      "std      4.987085e+01\n",
      "min      8.420974e+00\n",
      "25%      5.292969e+01\n",
      "50%      1.004395e+02\n",
      "75%      1.058594e+02\n",
      "max      9.874707e+03\n",
      "Name: purchase_amount_per_install, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(1,2))\n",
    "# scaler.fit(historical_transactions['purchase_amount'].values.reshape(-1,1))\n",
    "# scaled= scaler.transform(historical_transactions['purchase_amount'].values.reshape(-1,1))\n",
    "for df in [historical_transactions,new_transactions]:\n",
    "    min_amount = df['purchase_amount'].min()\n",
    "    df['purchase_amount_scaled'] = 100 * (df['purchase_amount'] - min_amount + 1)\n",
    "    mask = (df['installments']==-1) | (df['installments']==999)\n",
    "    df.loc[mask,'purchase_amount_per_install'] = df[mask]['purchase_amount_scaled'] \n",
    "    df.loc[~mask,'purchase_amount_per_install'] = df[~mask]['purchase_amount_scaled'] /  (df[~mask]['installments'] + 1)\n",
    "    print(df['purchase_amount_scaled'].describe())\n",
    "    print(df['purchase_amount_per_install'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "c6a56cc28a6229cde4992ff184a1a64d006fba2b"
   },
   "outputs": [],
   "source": [
    "def aggregate_transactions(history,agg_func,groupbyflag,prefix):\n",
    "    if groupbyflag=='card':\n",
    "        group_cols =['card_id']\n",
    "        newcoltemplate = 'card_'\n",
    "    elif groupbyflag=='merchant':\n",
    "        group_cols =['merchant_id']\n",
    "        newcoltemplate = 'merchant_'\n",
    "    elif groupbyflag=='both':\n",
    "        group_cols =['card_id','merchant_id']\n",
    "        newcoltemplate = 'card_merchant_'\n",
    "    agg_history = history[group_cols + list(agg_func.keys())].groupby(group_cols).agg(agg_func)\n",
    "    print('groupby complete')\n",
    "    new_columns = get_new_columns(prefix,agg_func)\n",
    "    agg_history.columns = new_columns\n",
    "#     agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    print('reset index complete')\n",
    "    #generate size of each card merchant combination\n",
    "#     agg_history[newcoltemplate +'size']=history[group_cols].groupby(group_cols).size().reset_index()\n",
    "    \n",
    "    return agg_history\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "6f4c741c9975dcc843f93512dabb932249be7073"
   },
   "outputs": [],
   "source": [
    "# mask1 = historical_transactions['category_3']=='A'\n",
    "# mask2 = historical_transactions['category_3']=='B'\n",
    "# mask3 = historical_transactions['category_3']=='C'\n",
    "# print(historical_transactions.loc[mask1,'card_id'].unique()[0:2])\n",
    "# print(historical_transactions.loc[mask2,'card_id'].unique()[0:2])\n",
    "# print(historical_transactions.loc[mask3,'card_id'].unique()[0:2])\n",
    "# mask1 = new_transactions['category_3']=='A'\n",
    "# mask2 = new_transactions['category_3']=='B'\n",
    "# mask3 = new_transactions['category_3']=='C'\n",
    "# print(new_transactions.loc[mask1,'card_id'].unique()[0:2])\n",
    "# print(new_transactions.loc[mask1,'card_id'].unique()[0:2])\n",
    "# print(new_transactions.loc[mask1,'card_id'].unique()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "b901580be848d9f64c87ee4b68830e0e6e2270c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexer: Index(['A', 'B', 'C'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#convert category 3 to numeric\n",
    "for df in [historical_transactions,new_transactions]:\n",
    "    df['category_3_raw'],indexer = pd.factorize(df['category_3'],sort=True)\n",
    "    df.loc[df['category_3']=='A','category_3_A'] = 1\n",
    "    df.loc[df['category_3']!='A','category_3_A'] = 0\n",
    "    df['category_2_raw'] = df['category_2'].fillna(-1)\n",
    "\n",
    "print('indexer:',indexer)\n",
    "#indexer is B,C,A so A,B,C becomes 2,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "178ea84ce310082077b5b95bcd223d4eb5018b88"
   },
   "outputs": [],
   "source": [
    "# mask1 = historical_transactions['card_id'].isin(['C_ID_4e6213e9bc', 'C_ID_0e171c1b48'])\n",
    "# # mask1 = historical_transactions['card_id']=='C_ID_0e171c1b48'\n",
    "# mask2 = historical_transactions['card_id'].isin(['C_ID_5037ff576e', 'C_ID_0e171c1b48'])\n",
    "# mask3 = historical_transactions['card_id'].isin(['C_ID_5037ff576e', 'C_ID_48fb13e70f'])\n",
    "# print(historical_transactions.loc[mask1,'category_3_raw'][0:2])\n",
    "# print(historical_transactions.loc[mask2,'category_3_raw'][0:2])\n",
    "# print(historical_transactions.loc[mask3,'category_3_raw'][0:2])\n",
    "# mask1 = new_transactions['card_id'].isin(['C_ID_a97720321f', 'C_ID_fb0875cd28'])\n",
    "# mask2 = new_transactions['card_id'].isin(['C_ID_a97720321f', 'C_ID_fb0875cd28'])\n",
    "# mask3 = new_transactions['card_id'].isin(['C_ID_a97720321f', 'C_ID_fb0875cd28'])\n",
    "# print(new_transactions.loc[mask1,'category_3_raw'][0:2])\n",
    "# print(new_transactions.loc[mask2,'category_3_raw'][0:2])\n",
    "# print(new_transactions.loc[mask3,'category_3_raw'][0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "335438a34e3a5b3aa04ff73a90d52a3c61836506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  3.  5.  2.  4.]\n",
      "-2652864.0\n",
      "58067480.0\n"
     ]
    }
   ],
   "source": [
    "print(historical_transactions['category_2_raw'].unique())\n",
    "mask = historical_transactions['category_2_raw']==-1\n",
    "print(historical_transactions.loc[mask,'category_2_raw'].astype('float32').sum())\n",
    "print(historical_transactions.loc[~mask,'category_2_raw'].astype('float32').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "ae6bb374598ad5e89fdb65fab5e9ded0fb1213ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['month_lag_1', 'month_lag_2'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dummies of month_lag\n",
    "dummies = pd.get_dummies(historical_transactions['month_lag'],prefix='month_lag')\n",
    "historical_transactions=pd.concat([historical_transactions,dummies],axis=1)\n",
    "dummies = pd.get_dummies(new_transactions['month_lag'],prefix='month_lag')\n",
    "new_transactions=pd.concat([new_transactions,dummies],axis=1)\n",
    "monthlag_dummies_cols = dummies.columns\n",
    "print(monthlag_dummies_cols)\n",
    "del dummies;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "c996ad431cc2d7ba6a26036e387f244790a2d4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.911236e+07\n",
      "mean     2.367025e-02\n",
      "std      1.520197e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-13, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     2.720401e-02\n",
      "std      1.626775e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-12, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     3.462028e-02\n",
      "std      1.828161e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-11, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     3.727121e-02\n",
      "std      1.894256e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-10, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     4.241236e-02\n",
      "std      2.015281e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-9, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     4.904604e-02\n",
      "std      2.159642e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-8, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     6.079356e-02\n",
      "std      2.389513e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-7, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     7.041847e-02\n",
      "std      2.558510e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-6, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     8.122976e-02\n",
      "std      2.731876e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-5, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     9.067643e-02\n",
      "std      2.871484e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-4, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     1.063346e-01\n",
      "std      3.082654e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-3, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     1.324962e-01\n",
      "std      3.390294e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-2, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     1.246010e-01\n",
      "std      3.302660e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_-1, dtype: float64\n",
      "count    2.911236e+07\n",
      "mean     1.192259e-01\n",
      "std      3.240541e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+00\n",
      "Name: month_lag_0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# historical_transactions.drop(monthlag_dummies_cols,axis=1,inplace=True)\n",
    "# new_transactions.drop(monthlag_dummies_cols,axis=1,inplace=True)\n",
    "histmonthlagcols = [col for col in historical_transactions.columns if 'month_lag_' in col]\n",
    "newmonthlagcols = [col for col in historical_transactions.columns if 'month_lag_' in col]\n",
    "for col in histmonthlagcols:\n",
    "    print(historical_transactions[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "34d28a6afb667980c52ef5a171709b04d8aa5bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby complete\n",
      "reset index complete\n",
      "transaction complete for: 0\n",
      "merge complete for: 0\n",
      "groupby complete\n",
      "reset index complete\n",
      "transaction complete for: 1\n",
      "merge complete for: 1\n"
     ]
    }
   ],
   "source": [
    "for i,df in enumerate([historical_transactions,new_transactions]):\n",
    "    agg_func = {\n",
    "        'purchase_amount_scaled' : ['min','max','var','mean','sum'],\n",
    "        'purchase_amount_per_install': ['min','max','var','mean','sum'],\n",
    "        'category_2_raw' :['sum','mean'],\n",
    "        'category_3_raw' :['sum','mean'],\n",
    "        'category_3_A' :['sum','mean'],\n",
    "        'city_id' : ['nunique'],\n",
    "        'state_id' : ['nunique']\n",
    "    }\n",
    "    \n",
    "    monthlagcols = [col for col in df.columns if 'month_lag_' in col]\n",
    "    for col in monthlagcols:\n",
    "        agg_func[col] =['sum','mean']\n",
    "    if (i==0):\n",
    "        prefix = 'hist'\n",
    "    else:\n",
    "        prefix = 'new_hist'\n",
    "        \n",
    "    agg_by_card = aggregate_transactions(df,agg_func,'card',prefix)\n",
    "\n",
    "    print('transaction complete for:',i)    \n",
    "    train = pd.merge(train, agg_by_card, on='card_id', how='left')\n",
    "    test = pd.merge(test, agg_by_card, on='card_id', how='left')\n",
    "    print('merge complete for:',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Rank Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_preproc(combined):\n",
    "    nullzerocols = ['new_hist_purchase_amount_scaled_max','new_hist_purchase_amount_scaled_min',\n",
    "                   'new_hist_purchase_amount_scaled_sum','new_hist_purchase_amount_scaled_mean',\n",
    "                'new_hist_purchase_amount_per_install_max','new_hist_purchase_amount_per_install_min',\n",
    "                'new_hist_purchase_amount_per_install_sum','new_hist_purchase_amount_per_install_mean']\n",
    "    nullmaxcols = ['new_hist_purchase_date_uptonow','new_hist_first_buy']\n",
    "    for df in [combined]:\n",
    "        df['purchase_amount_scaled_total'] = df['new_hist_purchase_amount_scaled_sum']+df['hist_purchase_amount_scaled_sum']\n",
    "        df['purchase_amount_per_install_total'] = df['new_hist_purchase_amount_per_install_sum']+df['hist_purchase_amount_per_install_sum']\n",
    "        for col in nullmaxcols:\n",
    "            maxval = df[col].max() + 30\n",
    "            df[col].fillna(maxval,inplace=True)\n",
    "        for col in nullzerocols:\n",
    "            df[col].fillna(0,inplace=True)\n",
    "            \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_newfeats_outlier(combined):\n",
    "    for df in [combined]:\n",
    "        df['hist_size_per_merchant'] = df['hist_card_id_size'] / df['hist_merchant_id_nunique']\n",
    "        df['hist_size_per_merchant_category'] = df['hist_card_id_size'] / df['hist_merchant_category_id_nunique']\n",
    "        df['hist_size_per_subsector'] = df['hist_card_id_size'] / df['hist_subsector_id_nunique']\n",
    "        df['hist_size_per_merchant_group'] = df['hist_card_id_size'] / df['hist_merchant_group_id_nunique']\n",
    "        df['hist_size_per_city'] = df['hist_card_id_size'] / df['hist_city_id_nunique']\n",
    "    \n",
    "    return combined\n",
    "        \n",
    "def generate_rank_outlier(combined):\n",
    "\n",
    "\n",
    "        rankdesccols = [\n",
    "'elapsed_time',\n",
    "'hist_size_per_merchant',\n",
    "'new_hist_first_buy',\n",
    "'new_hist_card_id_size',\n",
    "'hist_first_buy',\n",
    "'hist_category_1_mean',\n",
    "'hist_installments_mean',\n",
    "'hist_purchase_date_count_mean',\n",
    "'new_hist_purchase_date_uptonow',\n",
    "'hist_purchase_date_count_max',\n",
    "'hist_purchase_date_diff',\n",
    "'hist_month_lag_-4_sum',\n",
    "'hist_month_lag_-5_sum',\n",
    "'hist_month_lag_-6_sum',            \n",
    "]\n",
    "    \n",
    "        rankasccols = [\n",
    "        'hist_category_2_raw_mean',\n",
    "        'hist_purchase_amount_per_install_sum',\n",
    "        'hist_purchase_amount_per_install_mean',\n",
    "        'hist_card_id_size',\n",
    "        'new_hist_purchase_date_min',\n",
    "        'hist_purchase_date_min',\n",
    "        'hist_month_lag_0_sum',\n",
    "        'hist_month_lag_-1_sum',\n",
    "        'hist_month_lag_-2_sum',\n",
    "        'hist_month_lag_-3_sum',\n",
    "#         'hist_month_lag_-4_sum',\n",
    "#         'hist_month_lag_-5_sum',\n",
    "#         'hist_month_lag_-6_sum',\n",
    "        'hist_purchase_date_diff',\n",
    "       # 'hist_most_recent_sales_range_std',\n",
    "                       \n",
    "        'hist_authorized_flag_mean',\n",
    "        'hist_authorized_flag_sum',\n",
    "        'new_hist_card_id_size',\n",
    "        'new_hist_purchase_amount_per_install_sum',\n",
    "        'hist_category_3_A_mean',\n",
    "        'hist_month_lag_-12_mean',\n",
    "        'hist_month_lag_-13_sum',\n",
    "        'new_hist_purchase_date_diff',\n",
    "        'hist_purchase_amount_per_install_mean',\n",
    "\n",
    "        ]\n",
    "        \n",
    "        rankcols =[col for col in combined.columns if ('rank_' in col)]\n",
    "        if len(rankcols)!=0:\n",
    "            combined.drop(rankcols,axis=1,inplace=True)\n",
    "#         rankcols_train =[col for col in train.columns if ('rank_' in col)]\n",
    "#         if len(rankcols_train)!=0:\n",
    "#             train.drop(rankcols_train,axis=1,inplace=True)\n",
    "#         rankcols_test =[col for col in test.columns if ('rank_' in col)]\n",
    "#         if len(rankcols_test)!=0:\n",
    "#             test.drop(rankcols_test,axis=1,inplace=True)\n",
    "        for i,df in enumerate([combined]):\n",
    "            print('df :',i)\n",
    "            for col in rankasccols:\n",
    "                print('col:',col)\n",
    "                df['rank_'+col] =  df[col].rank()\n",
    "    #             df['rank_'+col] = weightasccols[i] * df[col].rank()\n",
    "\n",
    "            for col in rankdesccols:\n",
    "                print('col:',col)\n",
    "                df['rank_'+col] = df[col].rank(ascending=False)\n",
    "    #             df['rank_'+col] = weightdesccols[i] * df[col].rank(ascending=False)\n",
    "\n",
    "            rankcols =[col for col in df.columns if ('rank_' in col)\n",
    "                       & ('hist_purchase_amount_per_install_sum' !=col)\n",
    "#                        & ('hist_card_id_size' not in col)\n",
    "                        \n",
    "                      ]\n",
    "            df['rank_sum'] = df[rankcols].sum(axis=1) / 1E+5\n",
    "            df['rank_mean'] = df[rankcols].mean(axis=1) / 1E+5\n",
    "    #         weight_sum = (np.sum(np.array(weightasccols)) + np.sum(np.array(weightdesccols)))\n",
    "    #         df['rank_mean'] = df[rankcols].sum(axis=1) / (1E+5 * weight_sum)\n",
    "\n",
    "    #         df['rank_sum'] = df[rankcols].product(axis=1) / pow(10,len(rankdesccols) + len (rankasccols))\n",
    "\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_postproc(combined):\n",
    "    for df in [combined]:\n",
    "        df['rank_rank_sum']= df['rank_sum'].rank()\n",
    "        col = 'rank_hist_purchase_amount_per_install_sum'\n",
    "        df['rank_diff_' + col]= df[col] - df['rank_rank_sum']\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['istrain']=1\n",
    "test['istrain']=0\n",
    "combined = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Pre proc complete ********************************\n"
     ]
    }
   ],
   "source": [
    "combined = rank_preproc(combined)\n",
    "print()\n",
    "print('************ Pre proc complete ********************************')\n",
    "combined = gen_newfeats_outlier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df : 0\n",
      "col: hist_category_2_raw_mean\n",
      "col: hist_purchase_amount_per_install_sum\n",
      "col: hist_purchase_amount_per_install_mean\n",
      "col: hist_card_id_size\n",
      "col: new_hist_purchase_date_min\n",
      "col: hist_purchase_date_min\n",
      "col: hist_month_lag_0_sum\n",
      "col: hist_month_lag_-1_sum\n",
      "col: hist_month_lag_-2_sum\n",
      "col: hist_month_lag_-3_sum\n",
      "col: hist_purchase_date_diff\n",
      "col: hist_authorized_flag_mean\n",
      "col: hist_authorized_flag_sum\n",
      "col: new_hist_card_id_size\n",
      "col: new_hist_purchase_amount_per_install_sum\n",
      "col: hist_category_3_A_mean\n",
      "col: hist_month_lag_-12_mean\n",
      "col: hist_month_lag_-13_sum\n",
      "col: new_hist_purchase_date_diff\n",
      "col: hist_purchase_amount_per_install_mean\n",
      "col: elapsed_time\n",
      "col: hist_size_per_merchant\n",
      "col: new_hist_first_buy\n",
      "col: new_hist_card_id_size\n",
      "col: hist_first_buy\n",
      "col: hist_category_1_mean\n",
      "col: hist_installments_mean\n",
      "col: hist_purchase_date_count_mean\n",
      "col: new_hist_purchase_date_uptonow\n",
      "col: hist_purchase_date_count_max\n",
      "col: hist_purchase_date_diff\n",
      "col: hist_month_lag_-4_sum\n",
      "col: hist_month_lag_-5_sum\n",
      "col: hist_month_lag_-6_sum\n",
      "\n",
      "************ Generate Rank complete ********************************\n",
      "\n",
      "************ Post proc complete ********************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "combined = generate_rank_outlier(combined)\n",
    "print()\n",
    "print('************ Generate Rank complete ********************************')\n",
    "combined = rank_postproc(combined)\n",
    "print()\n",
    "print('************ Post proc complete ********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate back combined to train and test\n",
    "train=combined[combined['istrain']==1]\n",
    "test=combined[combined['istrain']==0]\n",
    "del combined;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['outliers']\n",
    "target.to_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "177769611efcb382e68f251e9f58d3ea2f4e00d2"
   },
   "outputs": [],
   "source": [
    "train.to_hdf('train_preproc.hdf',key='data')\n",
    "test.to_hdf('test_preproc.hdf',key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "55d012b4a0a4f523de539cb5ddab9b644459f29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save csv complete\n"
     ]
    }
   ],
   "source": [
    "train.to_csv('train_preproc.csv')\n",
    "test.to_csv('test_preproc.csv')\n",
    "print('save csv complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed : 0\n",
      "completed : 1\n",
      "completed : 2\n",
      "completed : 3\n",
      "completed : 4\n",
      "CPU times: user 7.53 s, sys: 168 ms, total: 7.7 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#read and save target encodings\n",
    "Path = '../input/elo-target-encoding/'\n",
    "for i in range(5):\n",
    "    \n",
    "    file = 'val_targetenc_feats'+str(i)+'.csv'\n",
    "    val = pd.read_csv(Path+file)\n",
    "    val.to_csv(file,index=False)\n",
    "    \n",
    "    file = 'train_targetenc_feats'+str(i)+'.csv'\n",
    "    train = pd.read_csv(Path+file)\n",
    "    train.to_csv(file,index=False)\n",
    "    \n",
    "    file = 'test_targetenc_feats'+str(i)+'.csv'\n",
    "    test = pd.read_csv(Path+file)\n",
    "    test.to_csv(file,index=False)\n",
    "    \n",
    "    print('completed :',i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "ec0cc7652926d4a56e79908eca9240e0567c9d67"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-7b1935733c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outliers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'outliers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "mask = train['target'] < -30\n",
    "train['outliers'] = 0\n",
    "train.loc[mask,'outliers'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
