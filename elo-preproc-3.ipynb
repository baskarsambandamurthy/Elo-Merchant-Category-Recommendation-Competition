{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold\nimport warnings\nimport time\nimport sys\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport gc\n\npd.options.display.max_rows = 999\npd.options.display.max_columns  = 999","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a059a8dcf9d93a650f1ccaa8e2bfa3e087219f3"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n## 1. Loading the data\n\nFirst, we load the `new_merchant_transactions.csv` and `historical_transactions.csv`. In practice, these two files contain the same variables and the difference between the two tables only concern the position with respect to a reference date.  Also, booleans features are made numeric:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7a7877dff5c337c09ca111cdcbf527362c9217c7"},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73e0936c181e4cec16da05d6987cd96b99ed87d1"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n## Feature engineering"},{"metadata":{"_uuid":"7493b32cb783d6fb6afdad60964eb41c9e42c2e3"},"cell_type":"markdown","source":"Then I define two functions that aggregate the info contained in these two tables. The first function aggregates the function by grouping on `card_id`:"},{"metadata":{"trusted":true,"_uuid":"82c25c7cd0d075195fb7bd63211c66f0dac9304b"},"cell_type":"code","source":"def aggregate_transactions(history,agg_func):\n    \n#     if 'purchase_date' in history.columns:\n#         history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n#                                           astype(np.int64) * 1e-9\n\n    group_cols =['card_id']\n    agg_history = history[group_cols + list(agg_func.keys())].groupby(['card_id']).agg(agg_func)\n    print('groupby complete')\n    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n    agg_history.reset_index(inplace=True)\n    print('reset index complete')\n    \n#     df = (history.groupby('card_id')\n#           .size()\n#           .reset_index(name='transactions_count'))\n    \n#     agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n    \n    return agg_history","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcf0403c10b8ee817257a51e5edf8f1f81fcd593"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## 3. Repeat Purchase Features"},{"metadata":{"trusted":true,"_uuid":"7c9e57b5817a106ee0ac1c3b8484c2c1f92ecadc"},"cell_type":"code","source":"def aggregate_transactions_by_merchant(history):\n#     if 'purchase_date' in history.columns:\n#         history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n#                                           astype(np.int64) * 1e-9\n   \n    group_cols = ['card_id','merchant_id']\n        \n    history.sort_values(by=group_cols + ['purchase_date'],inplace=True)\n    history[\"min_purchase_date\"] =history[group_cols +['purchase_date']].groupby(group_cols).transform('min')\n    history['purchase_duration'] = (history['purchase_date'].dt.date - history[\"min_purchase_date\"].dt.date).dt.days\n    history['repeat_purchase_amount'] = history['purchase_amount']\n    history.loc[history['purchase_duration']==0,'repeat_purchase_amount'] = 0\n    \n    agg_func_merch = {\n        'repeat_purchase_amount' : ['sum'],  # repeat total purchase amount for specific merchant\n         #purchase_duration - min:  repeat number of days lag from offer purchase to next purchase\n         #purchase_duration - max:  repeat number of days lag from offer purchase to last purchase\n        'purchase_duration' : ['max','min'],\n        'purchase_date' : ['count'] # repeat transaction count for specific merchant\n    }\n    \n    agg_history = history[group_cols + list(agg_func_merch.keys())].groupby(group_cols).agg(agg_func_merch)\n    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n    agg_history.reset_index(inplace=True)\n    return agg_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45883088a7b65b17c846b6b82d0190c33ce77492"},"cell_type":"code","source":"Path = '../input/elo-ref-2-data-conversion/'\n# historical_transactions = pd.read_hdf(Path+'historical_transactions.hdf')\nhistorical_transactions = pd.read_csv(Path+'historical_transactions.csv',index_col=0)\nprint('transactions read complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f916171921a171823fd1d0e1e535076d7969eaad"},"cell_type":"code","source":"# unnamedcols =[col for col in historical_transactions.columns if 'Unnamed' in col]\n# print(unnamedcols)\n# historical_transactions.drop(unnamedcols,axis=1,inplace=True)\n# # historical_transactions_sample = historical_transactions.sample(frac=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"becd9fa492c6d51664d42b1513e972a7b045cde9"},"cell_type":"code","source":"historical_transactions = reduce_mem_usage(historical_transactions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd78b0794fb21c5ea29f6741aff6559e0694c8d4"},"cell_type":"code","source":"historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'],infer_datetime_format=True)\nhist_agg_by_merchant = aggregate_transactions_by_merchant(historical_transactions)\nprint('aggregate_transactions_by_merchant complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b8a59802fce44c50984e76d4a087e98a65514fc"},"cell_type":"code","source":"# del historical_transactions\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f5b517c64db522ab91cf8f7b1320aa248436035"},"cell_type":"code","source":"agg_func = {\n    'repeat_purchase_amount_sum' : ['mean','min','max','std'],\n    'purchase_duration_max' : ['mean','min','max','std'],\n    'purchase_duration_min' : ['mean','min','max','std'],\n    'purchase_date_count' : ['mean','min','max','std']\n}\n\nhistorical_transactions_repeats = aggregate_transactions(hist_agg_by_merchant,agg_func)\nhistorical_transactions_repeats.columns = ['hist_' + c if c != 'card_id' else c for c in historical_transactions_repeats.columns]\nprint('aggregate_transactions complete')\n\ndel hist_agg_by_merchant;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45883088a7b65b17c846b6b82d0190c33ce77492"},"cell_type":"code","source":"# Path = '../input/elo-ref-3-preproc/'\n# train = pd.read_hdf(Path+'train_preproc.hdf')\n# print('train read complete')\n# test = pd.read_hdf(Path+'test_preproc.hdf')\n# print('test read complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d19bf699709415740da6f7a2d91998905fa1b597"},"cell_type":"code","source":"Path = '../input/elo-ref-3-preproc/'\ntrain = pd.read_csv(Path+'train_preproc.csv',index_col=0)\nprint('train read complete')\ntest = pd.read_csv(Path+'test_preproc.csv',index_col=0)\nprint('test read complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88de984c86f1c7b6fc1470d5f77817a886850ad1"},"cell_type":"code","source":"# unnamedcols =[col for col in train.columns if 'Unnamed' in col]\n# print(unnamedcols)\n# train.drop(unnamedcols,axis=1,inplace=True)\n# unnamedcols =[col for col in test.columns if 'Unnamed' in col]\n# print(unnamedcols)\n# test.drop(unnamedcols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6e8d58108b565aaf64b47c106835b0b68bc58c1"},"cell_type":"code","source":"train = pd.merge(train, historical_transactions_repeats, on='card_id', how='left')\ntest = pd.merge(test, historical_transactions_repeats, on='card_id', how='left')\nprint('history merge complete')\n\ndel historical_transactions_repeats;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70d555ff3e6434cf884b8d296ec19a5b54c0aeec"},"cell_type":"markdown","source":"**Merchant table features**"},{"metadata":{"trusted":true,"_uuid":"ff3c26f747a1aad92441df41a50431299d4f4704"},"cell_type":"code","source":"merchant = pd.read_csv('../input/elo-merchant-category-recommendation/merchants.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9f49f01c8ed7d8bb8bd2adc93570548b8e26f09"},"cell_type":"code","source":"# unnamedcols =[col for col in new_transactions.columns if 'Unnamed' in col]\n# print(unnamedcols)\n# new_transactions.drop(unnamedcols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fd1a748fb137ba0e92a113a3974466c064a5d41"},"cell_type":"code","source":"merchant['sum_sales_lag']  = merchant['avg_sales_lag3'] + merchant['avg_sales_lag6']  + merchant['avg_sales_lag12']\nmerchant['sum_purchases_lag']  = merchant['avg_purchases_lag3'] + merchant['avg_purchases_lag6']  + merchant['avg_purchases_lag12']\nmerchant['sum_sales_p_purchases_lag']  = merchant['sum_sales_lag'] + merchant['sum_purchases_lag']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2c58ae060edfbe33ff9b9cfcd78ac23ef55a299"},"cell_type":"code","source":"# outlier inf in avg_purchases_lag3, avg_purchases_lag6, avg_purchases_lag12\nmerchant.replace([np.inf, -np.inf], np.nan,inplace=True)\ncat_cols = ['most_recent_sales_range','most_recent_purchases_range','category_4']\nfor col in cat_cols:\n    print(col)\n    if col in ['most_recent_sales_range','most_recent_purchases_range']:\n        cat = pd.Categorical(merchant[col], categories=['E','D','C','B','A'],ordered=True)\n    else:\n        cat = merchant[col]\n    merchant[col],indexer = pd.factorize(cat)\n\n# merchant = pd.get_dummies(merchant, columns=['category_4'])\n\n# null in avg_sales_lag3, avg_sales_lag6, avg_sales_lag12, category_2\n# merchant.fillna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2f634cd0acb2616fd3410641f7a66c809b9e1a5"},"cell_type":"code","source":"#merge merchant with transactions\nexclude_cols = ['city_id','state_id','category_1','category_2','category_3','subsector_id','merchant_category_id']\nmerch_cols = [col for col in merchant.columns if col not in exclude_cols]\nhistorical_transactions_merch = pd.merge(historical_transactions[['merchant_id','card_id']],merchant[merch_cols],how='left',on='merchant_id')\nprint('historical_transactions complete')\ndel historical_transactions;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19b195b2f2178d804db16d589cb9efb0c67d5ca2"},"cell_type":"code","source":"historical_transactions_merch = reduce_mem_usage(historical_transactions_merch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0133108cf5550534147775161dc99d19dd91526e"},"cell_type":"code","source":"#wait for gc to collect\ntime.sleep(60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a089bc48da9ac0bc21bba512c1fec0a5b375141"},"cell_type":"code","source":"agg_func = {\n    'sum_sales_lag': ['sum','mean','min','max','std'],\n    'sum_sales_p_purchases_lag': ['sum','mean','min','max','std'],\n    'sum_purchases_lag': ['sum','mean','min','max','std'],\n    \n#     'most_recent_sales_range': ['mean','std','min','max'],\n#     'most_recent_purchases_range': ['mean','std','min','max'],\n#     'category_4': ['mean'],\n#     'merchant_group_id': ['nunique']\n    }\n\nagg_cols = list(agg_func.keys())\n\nhistory_merch1 = aggregate_transactions(historical_transactions_merch[['card_id']+agg_cols],agg_func)\nprint('historical_transactions complete')\nhistory_merch1.columns = ['hist_' + c if c != 'card_id' else c for c in history_merch1.columns]\n\n# del historical_transactions_merch;gc.collect()\nprint(history_merch1[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4f8aff22e11a2a600ea6b68eabe1a9f982f0956"},"cell_type":"code","source":"history_merch['card_id'][10050:10055] #325540,27","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f9d9ab7e05b5d672259cafcfc234320161de199"},"cell_type":"code","source":"agg_func = {\n  \n    'most_recent_sales_range': ['mean','std','min','max'],\n    'most_recent_purchases_range': ['mean','std','min','max'],\n    'category_4': ['mean'],\n    'merchant_group_id': ['nunique']\n    }\n\nagg_cols = list(agg_func.keys())\n\nhistory_merch2= aggregate_transactions(historical_transactions_merch[['card_id']+agg_cols],agg_func)\nprint('historical_transactions complete')\nhistory_merch2.columns = ['hist_' + c if c != 'card_id' else c for c in history_merch2.columns]\n\ndel historical_transactions_merch;gc.collect()\nprint(history_merch2[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f3467a5fc539d9e6069389ad63288afb7634ba1"},"cell_type":"code","source":"history_merch  = pd.concat([history_merch1, history_merch2.drop('card_id', axis=1)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c4883de8f6f51ea4f3c0e245173b612c9e99428"},"cell_type":"code","source":"del history_merch1, history_merch2;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dd773f12e3ecb3e7744e798c6e335eadb386c3e"},"cell_type":"code","source":"Path = '../input/elo-ref-2-data-conversion/'\n# new_transactions = pd.read_hdf(Path+'new_transactions.hdf')\nnew_transactions = pd.read_csv(Path+'new_transactions.csv',index_col=0)\nprint('new transactions read complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48f0492f7354317ff16eeaa0b3283350a21a2e6c"},"cell_type":"code","source":"new_transactions = reduce_mem_usage(new_transactions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce6215ae0d177a2975c934d83c2d18f64e3f8909"},"cell_type":"code","source":"new_transactions_merch = pd.merge(new_transactions[['merchant_id','card_id']],merchant[merch_cols],how='left',on='merchant_id')\nprint('new_transactions complete')\ndel new_transactions;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a089bc48da9ac0bc21bba512c1fec0a5b375141"},"cell_type":"code","source":"\nnew_merch = aggregate_transactions(new_transactions_merch[['card_id']+agg_cols],agg_func)\nprint('new_transactions complete')\nnew_merch.columns = ['new_' + c if c != 'card_id' else c for c in new_merch.columns]\nnew_merch[:5]\n\ndel new_transactions_merch\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ee124367f02ed3638c7f7fd14c6bc178368ffe"},"cell_type":"code","source":"# history_merch = history_merch.loc[:,~history_merch.columns.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f195f10f5a22a5d3c533cc06e43f1b8d7524de46"},"cell_type":"code","source":"#restore indices for merge\ntrain_index = train.index\ntest_index = test.index\n\ntrain = pd.merge(train, history_merch, on='card_id', how='left')\ntest = pd.merge(test, history_merch, on='card_id', how='left')\nprint('history merge complete')\n\ntrain = pd.merge(train, new_merch, on='card_id', how='left')\ntest = pd.merge(test, new_merch, on='card_id', how='left')\nprint('new merge complete')\n\ntrain.index = train_index\ntest.index = test_index\n\ndel history_merch, new_merch;gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18d2307599b17eeb7020d5da6148719107349218"},"cell_type":"markdown","source":"Save Data"},{"metadata":{"trusted":true,"_uuid":"5fb2d8ffbb3f1e0c586082dd2c3bad569c5ef922"},"cell_type":"code","source":"#Caution: data should be saved before deleting target\ntrain.to_hdf('train_preproc.hdf',key='data')\ntest.to_hdf('test_preproc.hdf',key='data')\nprint('save hdf file complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4955b78822eeab49b7b5ab62a02169ab27858319"},"cell_type":"code","source":"#Caution: data should be saved before deleting target\ntrain.to_csv('train_preproc.csv')\ntest.to_csv('test_preproc.csv')\nprint('save csv file complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adb285f8dde14f3996b26c881a90c11e6dcf6cee"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad10214f8d816cb23ec5d31569da5e56efe001a6"},"cell_type":"code","source":"# # train_temp = pd.read_csv('../input/elo-merchant-category-recommendation/train.csv')\n# target_temp = pd.read_hdf('../input/elo-ref-2-data-conversion/target.hdf')\n# target = target_temp['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d5778222197af64075816cb1b4feef5f3f198c8"},"cell_type":"code","source":"# train['target'] = target\ntrain['outliers'] = 0\ntrain.loc[train['target'] < -30, 'outliers'] = 1\ntrain['outliers'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d5778222197af64075816cb1b4feef5f3f198c8"},"cell_type":"code","source":"target= train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11ad5da13fabff9333066629c445334f05173ebd"},"cell_type":"code","source":"# del train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b0eba3e733ecdbab96d631eb46d42453d82aa20"},"cell_type":"code","source":"excluded_cols = ['card_id', 'first_active_month','target','outliers']\n\nfeatures = [c for c in train.columns if c not in excluded_cols]\nprint(excluded_cols)\n# categorical_feats = [c for c in features if 'feature_' in c ]\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e67399b25b3886e306b274069ab240af7d060397"},"cell_type":"markdown","source":"We then set the hyperparameters of the LGBM model:"},{"metadata":{"trusted":true,"_uuid":"c610f51450145101732f4e9ed3247f2a9fa0b091"},"cell_type":"code","source":"param = {'num_leaves': 31,\n         'min_data_in_leaf': 30, \n         'objective':'regression',\n         'max_depth': -1,\n         'learning_rate': 0.01,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1,\n         \"nthread\": 4,\n         \"random_state\": 4590}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7a7377cd7401f2cbd13ea707fbc2a2bebe229a6"},"cell_type":"markdown","source":"We now train the model. Here, we use a standard KFold split of the dataset in order to validate the results and to stop the training. Interstingly, during the writing of this kernel, the model was enriched adding new features, which improved the CV score. The variations observed on the CV were found to be quite similar to the variations on the LB: it seems that the current competition won't give us headaches to define the correct validation scheme:"},{"metadata":{"trusted":true,"_uuid":"5dd2ce40df20991a809208ac1578372a245875a4"},"cell_type":"code","source":"n_splits=5\nfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4590)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\nvalid_scores =[]\nfold_importance_df = pd.DataFrame()\nfold_importance_df[\"feature\"] = features\nfold_importance_df[\"importance\"] = 0\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train[features],train['outliers'].values)):\n    print(\"fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds = 100)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df[\"importance\"] += clf.feature_importance() / n_splits\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    valid_scores+=[clf.best_score['valid_0']['rmse']]\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint('valid scores:',valid_scores)\nprint(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b23550968ef3fb49ae0fcc5533551d702297c990","scrolled":false},"cell_type":"code","source":"# n_splits=5\n# folds = KFold(n_splits=n_splits, shuffle=True, random_state=15)\n# oof = np.zeros(len(train))\n# predictions = np.zeros(len(test))\n# start = time.time()\n# feature_importance_df = pd.DataFrame()\n# valid_scores =[]\n# fold_importance_df = pd.DataFrame()\n# fold_importance_df[\"feature\"] = features\n# fold_importance_df[\"importance\"] = 0\n# for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n#     print(\"fold nÂ°{}\".format(fold_))\n#     trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n#     val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n\n#     num_round = 10000\n#     clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds = 200)\n#     oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n#     fold_importance_df[\"importance\"] += clf.feature_importance() / n_splits\n# #     fold_importance_df[\"fold\"] = fold_ + 1\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n#     print(clf.best_score)\n#     valid_scores+=[clf.best_score['valid_0']['rmse']]\n#     predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\n# print('valid scores:',valid_scores)\n# print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a1f0a866e05f8a450960e2d787a641fc35991a1"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n## 4. Feature importance\nFinally, we can have a look at the features that were used by the model:"},{"metadata":{"trusted":true,"_uuid":"740bbd4abfc41ed73360e22ec42abaf1d4c6bffc"},"cell_type":"code","source":"# print(len(np.unique(oof)))\n# print(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a871fbcecc5a66e2580868aeeff8d4448c3ba1b"},"cell_type":"code","source":"np.savetxt('LGB_ref3_p_repeat.npy',oof)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d479e83032448481b40c216264a039cacdb2f9a1","scrolled":false},"cell_type":"code","source":"cols = (fold_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n\nbest_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,25))\nsns.barplot(x=\"importance\",\n            y=\"feature\",\n            data=best_features.sort_values(by=\"importance\",\n                                           ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90f4d4f572b7a8311431066354d267e9072e98f"},"cell_type":"code","source":"best_features=best_features.sort_values(by=\"importance\", ascending=False)\nbest_features.to_csv('best_features.csv')\nprint(best_features[:100])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"003ae1b1bd522b1b0d992ff220ed98d2a6d7477a"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n## 5. Submission\nNow, we just need to prepare the submission file:"},{"metadata":{"trusted":true,"_uuid":"82d5ac08a13603b2a66c59d98584c4b709daee2d"},"cell_type":"code","source":"sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv(\"submit_ref3_p_repeat.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1fecbc957898345ff6c4b136ce1692596caaf37"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}